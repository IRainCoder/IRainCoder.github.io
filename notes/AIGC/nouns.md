# 基础概念

## AIGC

AIGC（AI Generated Content）是指通过人工智能生成的内容，涵盖文本、图像、音频和视频等多种形式。

- **生成模型**
  
  - AIGC通常使用生成模型，如生成对抗网络（GANs）、变分自编码器（VAEs）和大规模预训练模型（如GPT、DALL-E）来创建内容。

- **应用场景**
  
  - AIGC在多个领域都有广泛应用，包括内容创作、游戏开发、广告营销、社交媒体、教育等。它可以自动生成文章、图像、音乐、视频等。

- **优点**
  
  - 提高效率：能够快速生成大量内容，节省人力资源。
  - 创造性：能够产生新的创意和想法，激发灵感。

- **缺点**
  
  - 质量控制：生成内容的质量可能不一致，有时需要人工审核和编辑。
  - 版权和道德：生成的内容可能涉及版权问题，尤其是使用了已有作品的风格或元素。

## AGI

AGI（Artificial General Intelligence，人工通用智能）是指一种能够理解、学习和应用知识以完成任何人类能完成的智能任务的人工智能。与当前的人工智能（通常称为弱AI或窄AI）不同，AGI具备广泛的认知能力和适应性，能够在多种领域和环境中表现出智能行为。

- **通用性**
  
  - AGI的核心特征是它的通用性，能够跨多个领域解决问题，而不仅限于特定任务或领域。

- **自主学习**
  
  - AGI能够通过经验自主学习，而不是依赖于大量标记数据进行训练。

## 大模型（Large Models）

大模型通常指参数量在亿级以上的深度学习模型，通过训练大量的数据来获得广泛的知识和能力。

- 闭源大模型包括 OpenAI 的 GPT 系列和 Google 的 BERT。

- 开源大模型以 Meta 的 Llama 系列，2024 年 4 月，Llama3 发布，包括 8B和 70B 模型。

## 上下文窗口

上下文窗口指的是模型一次可以处理的最大文本长度。这个长度通常用“tokens”（标记）来表示，每个标记可以是一个单词、子词或单个字符，具体取决于编码方式。

- **作用**
  
  - **记忆力**：上下文窗口越大，模型能够记住的文本信息越多，有助于理解长篇文章、对话等。
  
  - **连贯性**：在长文本生成时，较大的上下文窗口可以确保生成内容的连贯性和一致性，减少“遗忘”前文内容的情况。
  
  - **复杂任务**：处理更复杂的任务，例如多步骤推理或分析长文档中的逻辑关系。

- **限制**
  
  - **上下文窗口有限**：当输入超过上下文窗口时，模型会“遗忘”最早的部分内容，可能导致上下文信息的丢失。
  
  - **资源消耗**：随着上下文窗口的增加，模型对内存和计算资源的需求也随之增加。

- **实际应用**
  
  - **长文本处理**：在长文档总结、法律文书分析等场景中，较大的上下文窗口非常重要。
  - **对话系统**：在持续对话中，上下文窗口帮助模型记住对话历史，提高回复的相关性。

## 单位 B 和 T

在大模型和人工智能中，B（Billion）**和**T（Trillion）分别代表“十亿”和“万亿”，通常用来表示模型的参数数量：

- **B（Billion）**：十亿，例如“175B”表示一个模型有1750亿个参数。
- **T（Trillion）**：万亿，例如“1T”表示一个模型有1万亿个参数。

## 提示词工程

提示词工程（Prompt Engineering）是指设计和优化输入提示词（prompt）的过程，以便从生成式AI模型（如GPT、DALL-E等）获得更精确或更符合预期的输出。提示词工程在生成模型的实际应用中至关重要，因为不同的提示词设计会直接影响生成结果的质量和相关性。
